{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data: Movie Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program trains a classifier on movie reviews and predicts sentiment. \n",
    "Input: -> \"movie review text\"\n",
    "Output: -> \"positive review\" OR \"negative review\" \n",
    "\n",
    "We'll use this example to get familiar with how we use data to build a machine learning model.\n",
    "Try exploring how modifying the training and test data sets affects the behavior of the  classifier.\n",
    "\n",
    "Data from: http://www.nltk.org/nltk_data/\n",
    "\n",
    "Example based on: http://scikit-learn.org/dev/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 training examples\n"
     ]
    }
   ],
   "source": [
    "# Path to the training data\n",
    "moviedir = '../data/movie_reviews'\n",
    "# loading all files as training data. \n",
    "movie_train = load_files(moviedir, shuffle=True)\n",
    "print(\"Loaded \" + str(len(movie_train.data)) + \" training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting data: \n",
      "\n",
      "Target names: ['neg', 'pos']\n",
      "\n",
      "First line: arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \n",
      "it's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \n",
      "once again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \n",
      "in this so cal\n",
      "\n",
      "First file: movie_reviews/neg/cv405_21868.txt\n",
      "\n",
      "First file mapped to class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### Optional:\n",
    "# Make sure that the data is loaded correctly\n",
    "\n",
    "print(\"Inspecting data: \\n\")\n",
    "# target names (\"classes\") are automatically generated from subfolder names\n",
    "print(\"Target names: \" + str(movie_train.target_names) + \"\\n\")\n",
    "# First file seems to be about a Schwarzenegger movie. \n",
    "print(\"First line: \" + movie_train.data[0][:500] + \"\\n\")\n",
    "# first file is in \"neg\" folder\n",
    "print(\"First file: \" + movie_train.filenames[0] + \"\\n\")\n",
    "# first file is a negative review and is mapped to 0 index 'neg' in target_names\n",
    "print(\"First file mapped to class: \" + str(movie_train.target[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize movie_vector object, and then turn movie train data into a vector \n",
    "movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize)         # use all 25K words. 82.2% acc.\n",
    "# movie_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize, max_features = 3000) # use top 3000 words only. 78.5% acc.\n",
    "movie_counts = movie_vec.fit_transform(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the above breaks, uncomment and run the following line to fix the missing packages\n",
    "# nltk.download('punkt')\n",
    "# or, download manually from http://nltk.org/nltk_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of word 'screen' 19603\n",
      "dimensions: (2000, 25279)\n"
     ]
    }
   ],
   "source": [
    "###### Optional:\n",
    "# Examine formatted training data, what does it look like now?\n",
    "\n",
    "# 'screen' is found in the corpus, mapped to index 19637\n",
    "print(\"index of word 'screen' \" + str(movie_vec.vocabulary_.get('screen')))\n",
    "# huge dimensions! 2,000 documents, 25K unique terms. \n",
    "print(\"dimensions: \" + str(movie_counts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 25279)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Convert raw frequency counts into TF-IDF values\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "movie_tfidf = tfidf_transformer.fit_transform(movie_counts)\n",
    "\n",
    "\n",
    "# Same dimensions, now with tf-idf values instead of raw frequency counts\n",
    "print(movie_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ready to build a classifier. \n",
    "# We will use Multinominal Naive Bayes as our model\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "# from sklearn.cross_validation import train_test_split  # deprecated in 0.18\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    movie_tfidf, movie_train.target, test_size = 0.20, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Multimoda Naive Bayes classifier\n",
    "clf = MultinomialNB().fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results, find accuracy\n",
    "y_pred = clf.predict(docs_test)\n",
    "print(\"Accuracy: \")\n",
    "print(sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  31]\n",
      " [ 41 153]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the classifier on your own data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very short and fake movie reviews\n",
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "            'The acting was terrible', 'Tom Hardy shined through.', \n",
    "              'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', \n",
    "              \"We can't wait for the sequel!!\", '!', '?', 'I cannot recommend this highly enough', \n",
    "              'instant classic.', 'Simon Abkarian was amazing. His performance was Oscar-worthy.']\n",
    "reviews_new_counts = movie_vec.transform(reviews_new)\n",
    "reviews_new_tfidf = tfidf_transformer.transform(reviews_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have classifier make a prediction\n",
    "pred = clf.predict(reviews_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie was excellent' => pos\n",
      "'Absolute joy ride' => pos\n",
      "'The acting was terrible' => neg\n",
      "'Tom Hardy shined through.' => pos\n",
      "'This was certainly a movie' => neg\n",
      "'Two thumbs up' => neg\n",
      "'I fell asleep halfway through' => neg\n",
      "\"We can't wait for the sequel!!\" => neg\n",
      "'!' => neg\n",
      "'?' => neg\n",
      "'I cannot recommend this highly enough' => pos\n",
      "'instant classic.' => pos\n",
      "'Simon Abkarian was amazing. His performance was Oscar-worthy.' => pos\n"
     ]
    }
   ],
   "source": [
    "# print out results\n",
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%r => %s' % (review, movie_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
